{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,\n",
    "               positive)), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, \n",
    "               negative)), axis=-1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob.glob(\"images/*\"):\n",
    "#     print(os.path.splitext(os.path.basename(file))[0])\n",
    "# #         identity = os.path.splitext(os.path.basename(file))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are only going to use one image of each individual in our implementation. The reason is that the FaceNet network is powerful enough to only need one image of an individual to recognise them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_database():\n",
    "    path = \"Dataset\"\n",
    "    database = {}\n",
    "    for root, sub,filename in os.walk(path):\n",
    "        for file in filename:\n",
    "            cur_path = os.path.join(root,file)     \n",
    "\n",
    "            identity = cur_path.split(\"\\\\\")[1]\n",
    "            database[identity] = img_path_to_encoding(cur_path, FRmodel)\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_database():\n",
    "    database = {}\n",
    "    for file in glob.glob(\"images/*\"):\n",
    "        identity = os.path.splitext(os.path.basename(file))[0]\n",
    "        database[identity] = img_path_to_encoding(file, FRmodel)\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_face_recognizer(database):\n",
    "   \n",
    "    global ready_to_detect_identity\n",
    "\n",
    "    cv2.namedWindow(\"preview\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    while vc.isOpened():\n",
    "        ret, frame = vc.read()\n",
    "        if ret:\n",
    "            img = frame\n",
    "\n",
    "            # We do not want to detect a new identity while the program is in the process of identifying another person\n",
    "            if ready_to_detect_identity:\n",
    "                img = process_frame(img, frame, face_cascade)   \n",
    "\n",
    "            key = cv2.waitKey(100)\n",
    "            cv2.imshow(\"preview\", img)\n",
    "\n",
    "            if key == 27: # exit on ESC\n",
    "                break\n",
    "    cv2.destroyWindow(\"preview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "from multiprocessing.dummy import Pool\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "import win32com.client as wincl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 25\n",
    "ready_to_detect_identity = True\n",
    "windows10_voice_interface = wincl.Dispatch(\"SAPI.SpVoice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img, frame, face_cascade):\n",
    "    \n",
    "    global ready_to_detect_identity\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Loop through all the faces detected and determine whether or not they are in the database\n",
    "    identities = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1 = x-PADDING\n",
    "        y1 = y-PADDING\n",
    "        x2 = x+w+PADDING\n",
    "        y2 = y+h+PADDING\n",
    "\n",
    "        img = cv2.rectangle(frame,(x1, y1),(x2, y2),(255,0,0),2)\n",
    "\n",
    "        identity = find_identity(frame, x1, y1, x2, y2)\n",
    "\n",
    "        if identity is not None:\n",
    "            identities.append(identity)\n",
    "\n",
    "    if identities != []:\n",
    "        cv2.imwrite('example.png',img)\n",
    "\n",
    "        ready_to_detect_identity = False\n",
    "        pool = Pool(processes=1) \n",
    "        # We run this as a separate process so that the camera feedback does not freeze\n",
    "        pool.apply_async(welcome_users, [identities])\n",
    "    return img\n",
    "\n",
    "def find_identity(frame, x1, y1, x2, y2):\n",
    " \n",
    "    height, width, channels = frame.shape\n",
    "    # The padding is necessary since the OpenCV face detector creates the bounding box around the face and not the head\n",
    "    part_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]\n",
    "#     part_image = frame[(y1):(height), ( x1):(width)]\n",
    "    \n",
    "#     print( who_is_it(part_image, database, FRmodel))\n",
    "    return who_is_it(part_image, database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 96, 96)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# testpath = \"C:/Users/spari/Projects/SDKART/ACE/obama.jpg\"\n",
    "# img = cv2.imread(testpath)\n",
    "# img = cv2.resize(img, (96, 96)) \n",
    "# # img = image[...,::-1]\n",
    "\n",
    "\n",
    "# img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "# # cv2.imwrite('iee.png',img)\n",
    "# # x_train = np.array([img])\n",
    "# # embedding = model.predict_on_batch(x_train)\n",
    "# # process_frame(img,img,face_cascade)\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image, database, model):\n",
    "    encoding = img_to_encoding(image, model)\n",
    "    \n",
    "    min_dist = 100\n",
    "    identity = None\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        dist = np.linalg.norm(db_enc - encoding)\n",
    "        print('distance for %s is %s' %(name, dist))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    if min_dist > 0.70:\n",
    "        return \"No one\"\n",
    "    else:\n",
    "        print(\"IDD\", identity)\n",
    "        cv2.putText(image,identity, (80,80), cv2.FONT_HERSHEY_SIMPLEX, 2, 2, 2)\n",
    "        return identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welcome_users(identities):\n",
    "    \"\"\" Outputs a welcome audio message to the users \"\"\"\n",
    "    global ready_to_detect_identity\n",
    "    welcome_message = 'Welcome '\n",
    "\n",
    "    if len(identities) == 1:\n",
    "        welcome_message += '%s, have a nice day.' % identities[0]\n",
    "    else:\n",
    "        for identity_id in range(len(identities)-1):\n",
    "            welcome_message += '%s, ' % identities[identity_id]\n",
    "        welcome_message += 'and %s, ' % identities[-1]\n",
    "        welcome_message += 'have a nice day!'\n",
    "\n",
    "    windows10_voice_interface.Speak(welcome_message)\n",
    "\n",
    "    # Allow the program to start detecting identities again\n",
    "    ready_to_detect_identity = True\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     database = prepare_database()\n",
    "#     webcam_face_recognizer(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = prepare_database()\n",
    "# webcam_face_recognizer(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance for Pakhi is 0.848562\n",
      "distance for Prateek is 0.873412\n",
      "distance for Rishabh is 0.835415\n",
      "distance for test is 0.818318\n",
      "distance for Pakhi is 0.896077\n",
      "distance for Prateek is 0.926984\n",
      "distance for Rishabh is 0.786255\n",
      "distance for test is 0.902738\n",
      "distance for Pakhi is 0.969004\n",
      "distance for Prateek is 0.914785\n",
      "distance for Rishabh is 0.875001\n",
      "distance for test is 0.961715\n",
      "distance for Pakhi is 0.810441\n",
      "distance for Prateek is 0.815598\n",
      "distance for Rishabh is 0.774394\n",
      "distance for test is 0.976657\n",
      "distance for Pakhi is 0.83163\n",
      "distance for Prateek is 0.860425\n",
      "distance for Rishabh is 0.716925\n",
      "distance for test is 0.935602\n",
      "distance for Pakhi is 0.879699\n",
      "distance for Prateek is 0.956492\n",
      "distance for Rishabh is 0.851071\n",
      "distance for test is 0.891471\n",
      "distance for Pakhi is 0.864096\n",
      "distance for Prateek is 0.872378\n",
      "distance for Rishabh is 0.751984\n",
      "distance for test is 0.927888\n",
      "distance for Pakhi is 0.750772\n",
      "distance for Prateek is 0.910714\n",
      "distance for Rishabh is 0.758276\n",
      "distance for test is 0.725439\n",
      "distance for Pakhi is 0.79931\n",
      "distance for Prateek is 0.988338\n",
      "distance for Rishabh is 0.842204\n",
      "distance for test is 0.891155\n",
      "distance for Pakhi is 1.13814\n",
      "distance for Prateek is 1.15699\n",
      "distance for Rishabh is 1.15672\n",
      "distance for test is 0.984641\n"
     ]
    }
   ],
   "source": [
    "webcam_face_recognizer(database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
